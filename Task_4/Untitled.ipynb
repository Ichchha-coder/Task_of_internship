{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef00530",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b15099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the FeatureExtractor\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, weights_path='feature_extractor.pth'):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        # Define the architecture\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Load pre-trained weights on CPU\n",
    "        state_dict = torch.load(weights_path, map_location=torch.device('cpu'))\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the FeatureExtractor\n",
    "feature_extractor = FeatureExtractor()\n",
    "\n",
    "# Define the Multi-Task Model\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, feature_extractor):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.digit_classifier = nn.Linear(64 * 7 * 7, 10)  # Adjust the input size based on feature extractor's output\n",
    "        self.binary_classifier = nn.Linear(64 * 7 * 7, 2)  # Adjust the input size based on feature extractor's output\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(features.size(0), -1)  # Flatten the features\n",
    "        digit_logits = self.digit_classifier(features)\n",
    "        binary_logits = self.binary_classifier(features)\n",
    "        return digit_logits, binary_logits\n",
    "\n",
    "# Create an instance of the MultiTaskModel\n",
    "model = MultiTaskModel(feature_extractor)\n",
    "\n",
    "# Define the loss functions and optimizer\n",
    "criterion_digit = nn.CrossEntropyLoss()\n",
    "criterion_binary = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Load the MNIST dataset and preprocess it\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Training\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        digit_logits, binary_logits = model(data)\n",
    "        loss_digit = criterion_digit(digit_logits, target)\n",
    "        binary_target = (target > 5).long()\n",
    "        loss_binary = criterion_binary(binary_logits, binary_target)\n",
    "        loss = loss_digit + loss_binary\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "correct_digit, correct_binary = 0, 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        digit_logits, binary_logits = model(data)\n",
    "        _, predicted_digit = digit_logits.max(1)\n",
    "        _, predicted_binary = binary_logits.max(1)\n",
    "        correct_digit += predicted_digit.eq(target).sum().item()\n",
    "        correct_binary += predicted_binary.eq((target > 5).long()).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "digit_accuracy = 100.0 * correct_digit / total\n",
    "binary_accuracy = 100.0 * correct_binary / total\n",
    "\n",
    "print(f\"Digit Classification Accuracy: {digit_accuracy:.2f}%\")\n",
    "print(f\"Binary Classification Accuracy: {binary_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6a67e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
